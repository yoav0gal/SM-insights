{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic based clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of our project is to group YouTube comments together based on their topics.\n",
    "\n",
    "This notebook will explore different clustering algorithms, benchmark them, and recommend one that is most suitable for our problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumptions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook assumes the following: \n",
    "- Comments have already been cleaned and encoded. \n",
    "- Comments encoding have been reduced into a 2 dimensional space.\n",
    "\n",
    "Currently, we did not prefect these steps, so here is a short and imperfect implementation of these so we can start working. [link to notebook](./assumptions.ipynb)\n",
    "\n",
    "> We assume that the data is encoded properly and that by mesuring the distance between comments, we can cluster them based on topics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithms\n",
    "- Agglomerative\n",
    "- K-Means\n",
    "- HDBSCAN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Benchmarks\n",
    "- Davies-Bouldin\n",
    "- Silhouette\n",
    "- Calinski-Harabasz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-learn pandas numpy tqdm python-dotenv google-genai plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmarks utills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score\n",
    "\n",
    "def clustering_evaluation(X, labels):\n",
    "    silhouette = silhouette_score(X, labels)\n",
    "    davies_bouldin = davies_bouldin_score(X, labels)\n",
    "    calinski_harabasz = calinski_harabasz_score(X, labels)\n",
    "    \n",
    "    return silhouette, davies_bouldin, calinski_harabasz\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First step, lets just put our points on the plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"./datasets/with-assumptions/jack_vs_calley_1000.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "if df['encoded'].dtype == 'object' and isinstance(df['encoded'].iloc[0], str):\n",
    "    df['encoded'] = df['encoded'].apply(lambda x: ast.literal_eval(x))\n",
    "    \n",
    "df['x'] = df['encoded'].apply(lambda x: x[0])\n",
    "df['y'] = df['encoded'].apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "def plot_scatter(df):        \n",
    "    fig = px.scatter(\n",
    "        df, \n",
    "        x='x', \n",
    "        y='y',\n",
    "        hover_data=['text'],\n",
    "        title='Visualization of Encoded Points',\n",
    "        labels={'x': 'Dimension 1', 'y': 'Dimension 2'},\n",
    "        opacity=0.7\n",
    "    )\n",
    "\n",
    "    # Improve layout\n",
    "    fig.update_layout(\n",
    "        plot_bgcolor='white',\n",
    "        width=900,\n",
    "        height=700\n",
    "    )\n",
    "\n",
    "    # Add grid lines\n",
    "    fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')\n",
    "    fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGray')\n",
    "\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can not see any pattern at this momnet.\n",
    "To make it more easly ilustrated, lets just pick 50 random comments.\n",
    "Also, we can assume the data is that clusted cuz of the huge dimensionality reduction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_50_df = df.sample(n=50, random_state=42)\n",
    "plot_scatter(sample_50_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run some clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional Clustering Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Means\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HDBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation and Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Silhouette Score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calinski-Harabasz Index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Algorithm Comparison and Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Visualization and Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Clustering with LLM Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Recommendations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BERTopic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
