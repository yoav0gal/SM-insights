{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Labeling Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports And Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\ilai\\anaconda3\\lib\\site-packages (1.5.3)\n",
      "Requirement already satisfied: bertopic in c:\\users\\ilai\\anaconda3\\lib\\site-packages (0.17.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\ilai\\anaconda3\\lib\\site-packages (4.50.1)\n",
      "Requirement already satisfied: keybert in c:\\users\\ilai\\anaconda3\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: google-generativeai in c:\\users\\ilai\\anaconda3\\lib\\site-packages (0.8.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\ilai\\anaconda3\\lib\\site-packages (1.24.4)\n",
      "Requirement already satisfied: faker in c:\\users\\ilai\\anaconda3\\lib\\site-packages (37.1.0)\n",
      "Requirement already satisfied: grpcio==1.60.0 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (1.60.0)\n",
      "Requirement already satisfied: grpcio-tools==1.60.0 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (1.60.0)\n",
      "Requirement already satisfied: google in c:\\users\\ilai\\anaconda3\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: datasets in c:\\users\\ilai\\anaconda3\\lib\\site-packages (2.19.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from grpcio-tools==1.60.0) (58.0.4)\n",
      "Requirement already satisfied: protobuf<5.0dev,>=4.21.6 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from grpcio-tools==1.60.0) (4.25.8)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: sentence-transformers>=0.4.1 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from bertopic) (4.0.1)\n",
      "Requirement already satisfied: plotly>=4.7.0 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from bertopic) (6.0.0)\n",
      "Requirement already satisfied: umap-learn>=0.5.0 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from bertopic) (0.5.7)\n",
      "Requirement already satisfied: scikit-learn>=1.0 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from bertopic) (1.6.1)\n",
      "Requirement already satisfied: hdbscan>=0.8.29 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from bertopic) (0.8.40)\n",
      "Requirement already satisfied: tqdm>=4.41.1 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from bertopic) (4.67.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from transformers) (0.29.3)\n",
      "Requirement already satisfied: requests in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from transformers) (2021.8.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from transformers) (3.3.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: rich>=10.4.0 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from keybert) (13.9.4)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from google-generativeai) (2.166.0)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from google-generativeai) (2.24.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from google-generativeai) (2.38.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: pydantic in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from google-generativeai) (2.10.6)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: tzdata in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from faker) (2025.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from google) (4.10.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from datasets) (2024.3.1)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from datasets) (3.12.15)\n",
      "Requirement already satisfied: pyarrow-hotfix in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from datasets) (0.7)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.7.0)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (25.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (1.20.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (6.6.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from aiohttp->datasets) (0.3.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (1.69.2)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (1.60.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: joblib>=1.0 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from hdbscan>=0.8.29->bertopic) (1.4.2)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from hdbscan>=0.8.29->bertopic) (1.10.1)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from plotly>=4.7.0->bertopic) (1.25.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.17.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from requests->transformers) (3.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from rich>=10.4.0->keybert) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from rich>=10.4.0->keybert) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.4.0->keybert) (0.1.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0->bertopic) (3.6.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic) (2.1.0+cpu)\n",
      "Requirement already satisfied: Pillow in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from sentence-transformers>=0.4.1->bertopic) (8.4.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (2.11.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (2.6.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from tqdm>=4.41.1->bertopic) (0.4.4)\n",
      "Requirement already satisfied: pynndescent>=0.5 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from umap-learn>=0.5.0->bertopic) (0.5.13)\n",
      "Requirement already satisfied: numba>=0.51.2 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from umap-learn>=0.5.0->bertopic) (0.60.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from numba>=0.51.2->umap-learn>=0.5.0->bertopic) (0.43.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from beautifulsoup4->google) (2.2.1)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from pydantic->google-generativeai) (2.27.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ilai\\anaconda3\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers>=0.4.1->bertopic) (1.2.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\ilai\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\ilai\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\ilai\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\ilai\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\ilai\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\ilai\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pandas bertopic transformers keybert google-generativeai numpy faker grpcio==1.60.0 grpcio-tools==1.60.0 google datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bertopic import BERTopic\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from keybert import KeyBERT\n",
    "import google.generativeai as genai\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"../\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import utils.gemini_client as gemini_client\n",
    "\n",
    "def reload_utils():\n",
    "    importlib.reload(gemini_client)\n",
    "\n",
    "reload_utils()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=gemini_client.GEMINI_API_KEY)\n",
    "\n",
    "gemini_model = genai.GenerativeModel(\"gemini-2.0-flash-lite\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load CSV\n",
    "df = pd.read_csv(\"..\\data\\datasets\\youtube_comments\\jack_vs_calley_1000.csv\") \n",
    "texts = df[\"text\"].dropna().astype(str).tolist() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intruduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic modeling is widely used to discover hidden structures in text datasets. However, labeling the discovered topics is often challenging. Traditional methods generate labels by extracting keywords, which might not always convey the full semantic meaning of the topic.\n",
    "\n",
    "In this project, we aim to:\n",
    "1. Apply BERTopic to cluster YouTube comments into topics.\n",
    "2. Generate labels using:\n",
    "    - BERTopic's built-in labeling\n",
    "    - KeyBERT keyword extraction\n",
    "    - Google Gemini LLM summarization\n",
    "3. Rate the quality of labels generated by each method.\n",
    "\n",
    "The goal is to understand whether LLMs can outperform classical methods in generating interpretable topic labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process consists of the following steps:\n",
    "\n",
    "1. **Clustering**:  \n",
    "   - We use BERTopic with a pre-trained `all-MiniLM-L6-v2` embedding model to cluster the comments into topics.\n",
    "\n",
    "2. **Labeling**:\n",
    "   - **BERTopic**: Extracts representative keywords for each topic.\n",
    "   - **KeyBERT**: Extracts keywords based on embedding similarity.\n",
    "   - **Gemini**: Receives comments per topic and returns up to 5 keywords describing the topic.\n",
    "\n",
    "3. **Evaluation**:  \n",
    "   - We assess the quality of the generated labels using three evaluation methods:\n",
    "     1. **Cluster Purity** (`compute_cluster_purity`): Measures how well the assigned labels capture the internal consistency of each cluster.\n",
    "     2. **Label Stability** (`compute_label_stability`): Evaluates the robustness of labels when the data or clustering slightly changes.\n",
    "     3. **Gemini-based Rating**: Uses Google Gemini to provide an external qualitative assessment of the labels, scoring each method from 1 to 100 based on clarity, relevance, and descriptiveness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words=\"english\", ngram_range=(1, 3), min_df=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERTopic Clustering ---\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "topic_model = BERTopic(embedding_model=embedding_model, vectorizer_model=vectorizer)\n",
    "topics, probs = topic_model.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from typing import Dict, List, Sequence\n",
    "\n",
    "from bertopic import BERTopic\n",
    "from keybert import KeyBERT\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "class TopicLabeler:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        texts: Sequence[str],\n",
    "        topics: Sequence[int],\n",
    "    ) -> None:\n",
    "        self.texts: List[str] = list(texts)\n",
    "        self.topics: List[int] = list(topics)\n",
    "        self.topic_ids: List[int] = sorted({t for t in self.topics if t != -1})\n",
    "\n",
    "        self._topic_docs: Dict[int, List[str]] = {tid: [] for tid in self.topic_ids}\n",
    "        for txt, tid in zip(self.texts, self.topics):\n",
    "            if tid != -1:\n",
    "                self._topic_docs[tid].append(txt)\n",
    "\n",
    "    def label_with_bertopic(\n",
    "    self,\n",
    "    topic_model: BERTopic,\n",
    "    n_phrases: int = 6,\n",
    "    phrase_len: int = 3,\n",
    "    ) -> Dict[int, List[str]]:\n",
    "        labels: Dict[int, List[str]] = {}\n",
    "\n",
    "        for tid in self.topic_ids:\n",
    "            topic = topic_model.get_topic(tid)\n",
    "            if not topic:\n",
    "                continue\n",
    "\n",
    "            top_words = [word.replace(\"_\", \" \") for word, _ in topic[:15]]\n",
    "\n",
    "            phrases = [\n",
    "                \" \".join(top_words[i:i + phrase_len])\n",
    "                for i in range(len(top_words) - phrase_len + 1)\n",
    "            ]\n",
    "\n",
    "            labels[tid] = phrases[:n_phrases]\n",
    "\n",
    "        return labels\n",
    "   \n",
    "   \n",
    "    def label_with_keybert(\n",
    "        self,\n",
    "        embedding_model: SentenceTransformer,\n",
    "        top_n: int = 5,\n",
    "        ngram_range: tuple[int, int] = (2, 4),\n",
    "    ) -> Dict[int, List[str]]:\n",
    "        kw_model = KeyBERT(model=embedding_model)\n",
    "        labels: Dict[int, List[str]] = {}\n",
    "\n",
    "        for tid, docs in self._topic_docs.items():\n",
    "            if not docs:\n",
    "                continue\n",
    "\n",
    "            keywords = kw_model.extract_keywords(\n",
    "                \" \".join(docs),\n",
    "                keyphrase_ngram_range=ngram_range,\n",
    "                top_n=top_n,\n",
    "            )\n",
    "            labels[tid] = [kw for kw, _ in keywords]\n",
    "\n",
    "        return labels\n",
    "\n",
    "    def label_with_gemini(\n",
    "        self,\n",
    "        model, \n",
    "        max_words: int = 6,\n",
    "        max_docs: int = 5,\n",
    "    ) -> Dict[int, List[str]]:\n",
    "        labels: Dict[int, List[str]] = {}\n",
    "\n",
    "        for tid, docs in self._topic_docs.items():\n",
    "            if len(docs) < 3:\n",
    "                continue\n",
    "\n",
    "            payload = \"\\n\".join(doc[:300] for doc in docs[:max_docs])\n",
    "            prompt = (\n",
    "                \"You are given YouTube comments that all share one topic.\\n\"\n",
    "                f\"Return up to {max_words} short keywords or phrases that best \"\n",
    "                \"summarise the topic, comma-separated only.\\n\\n\"\n",
    "                f\"{payload}\"\n",
    "            )\n",
    "\n",
    "            chat = model.start_chat()\n",
    "            response = chat.send_message(prompt)\n",
    "\n",
    "            tokens = [t.strip() for t in response.text.split(\",\") if t.strip()]\n",
    "            labels[tid] = tokens\n",
    "\n",
    "        return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeler = TopicLabeler(texts, topics)\n",
    "bertopic_labels = labeler.label_with_bertopic(topic_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "keybert_labels = labeler.label_with_keybert(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_labels = labeler.label_with_gemini(gemini_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {\"BERTopic\": bertopic_labels, \"KeyBERT\": keybert_labels, \"Gemini\": gemini_labels}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluationg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Inspection - General Topic Overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to better understand the quality of the generated labels, we implement a simple visualization function. The function `show_topic_full` displays, for a given topic:\n",
    "1. The labels generated by each labeling method.\n",
    "2. The list of all comments associated with the selected topic.\n",
    "\n",
    "Since topic modeling is an unsupervised task, evaluating the \"correctness\" of labels is inherently challenging. There is no absolute ground truth, and even similar labels can have different levels of usefulness depending on human interpretation. Therefore, visual inspection â€” simulating how a human would read the comments and judge the relevance of the labels â€” is essential.\n",
    "\n",
    "This motivated us to later employ a Large Language Model (LLM) as an evaluator, aiming to approximate human judgment when rating the quality of the labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Topic 1 ===\n",
      "\n",
      "--- BERTopic Labels ---\n",
      "jack think guy, think guy dr jack, guy dr jack jack kruse, dr jack jack kruse say, jack kruse say kruse, say kruse podcast\n",
      "\n",
      "--- KeyBERT Labels ---\n",
      "healthcare jack gets doing, discussion need dr jacks, glad say dr jack, dr jack got, dr jack got mrna\n",
      "\n",
      "--- Gemini Labels ---\n",
      "Jack Kruse, podcasts, controversial topics, messenger critique, Bitcoin\n",
      "\n",
      "--- All Texts in Topic 1 ---\n",
      "1. Why would Jack turn down Rogan and Tucker? He could call them out just like he did this guy\n",
      "2. Jack Kruse is goat, and a bitcoiner. lets gooo.\n",
      "3. Iâ€™ve lost respect for Jack\n",
      "4. I've tried to make it through this podcast 3 times!!! Danny Jones -- if you are going to cover these highly controversial topics you need to learn how to moderate your damn guests! Jack may have an important message but he SUCKS BALLS as a messenger. Ugh!!!!!!!!!!!!\n",
      "5. Jack for president\n",
      "6. Heâ€™s very nervous, and desperate for Jack to stop, but Jack smells fear.. and knows thereâ€™s a reason for it â€¦ â€˜jack, jack, jack, â€˜ ðŸ˜‚\n",
      "7. Urgh brother what that\n",
      "8. Iâ€™m all for what him and his sister are trying to do with the food â€¦ Iâ€™ve been sick for over 5 years post covid â€¦. But Jack is right he does sound just like a typical politician I think he truly wants to be in the political game and thatâ€™s all he cares aboutâ€¦. People need to go to jail over this shit or it will never stop â€¦ so I think Jack wins this fight. Any legit doctors read this I would really love some help to get my Heath back â€¦ Jack please reach out if you read this. My gut is fucked and Iâ€™ve been listening to what you have out there and think you could help me get my Heath back.\n",
      "9. Kruse is a bullshit artist\n",
      "10. I found it hard to listen to due to that fuck wit Jack not being able to hold a rational debate just jumping from conspiracy to conspiracy bringing up his mothers death and death certificate. And interrupting constantly\n",
      "11. The dude is too much. He tries talking over her every words and then wile he talkin. Shuu her.  What a narcissist.  Another prick with a title thinks better everyone else.  But I bet give him 6 months were no daddy money and no help and toss out. Like rest of country. See were is 6 months. He be dead from od or in jail. It's almost against law to be poor in this country.  Jail is full poor ppl.  But if u got oj money or MJ money.\n",
      "12. Jack your mean\n",
      "13. Jack said stand ford is Dark who else went to stand\n",
      "14. Jack stop being ANGRY\n",
      "15. Jack Kruse is the man!\n",
      "16. Iâ€™ll talk to you Jack!\n",
      "17. I want Jack to read all comments and replies.  Other than just getting everyone agreeing with him.\n",
      "18. Iâ€™m sure the majority of humans stand with Uncle Jack and in regards to the other guy all I have to say is â€œHOLD MY BEERâ€\n",
      "19. Jack thinks he's inspector gadget ðŸ˜‚\n",
      "20. Singularly the worst pod cast ever. The Jack and Mary are obnoxious and cannot even follow any logical series of questions. Itâ€™s all conspiracy b. s.\n",
      "21. Jack did his research and seems to have the receipts.\n",
      "22. Jack Kruse is a lunatic who is wrong about almost everything.\n",
      "23. Jack and his hysteria are why we can't get things done. Who can take him seriously with his attitude? He is the flipside of a coin with a screeching liberal cat lady on the other side. He has so much valid information, but he's useless to the cause. Either help for real or get out of the way.\n",
      "24. Good for you, Jack.\n",
      "25. He is a slippery sucker you guys...however he is beautifully nice...\n",
      "26. Jack jack jack jack jack ðŸ¥´ðŸ˜³\n",
      "27. 1:24:20 Facts, there are realities to the world if you wanna get anything done... then proceeds to talk about an ammendment that got nowhere because of standing 100% on principle.Well I guess I'm in the minority but this Jack dude seems like a nut. He starts out super hostile and by the end is saying Tucker Carlson and Joe Rogan are part of the problem... well buddy if that's true go live on pluto I guess lol.And no I've never been vaxxed, I know many vaxxed injured, am generally a contrarion etc.Do I think he's bringing up interesting questions? Sure. But not in a respectful or productive way.\n",
      "28. Jack is ABSOLUTELY CORRECT!!! Listen to this man.\n",
      "29. Jack's fury is puzzling\n",
      "30. Jack jack Jack jack Jack jack Jack jack Jack jack Jack jack let me talk.. LMAOThis guy reminds me of justin trudeau abd wont let jack speak\n",
      "31. For those if you who have not watched jacks other big podcast i really recommend it so you all understand why he's so angry. I highly recommend it will open your eyes\n",
      "32. He hasn't lost loved ones yet due to that garbage\n",
      "33. Jack really my type of guy when it comes to these matters.\n",
      "34. Jack Kruse has balls as big as church bells! Legend! Glad he is fighting for our health!\n",
      "35. Never seen this guy Jack but he's an aggressive asshole and it's a real distraction from the conversation. Almost unlistenabke in some places because of his yelling.\n",
      "36. I had never heard of this Means jack@ss until today. Holy cow is he totally and utterly obnoxious, and has zero idea how to have a conversation or dialogue. I hope to never hear from him again.\n",
      "37. Half of the podcast we listen word \"jack?\" \"Jack\"? Waste of tyme this debate\n",
      "38. I don't disagree with Jack but he really needs to unbunch his panties and learn how to have a conversation like an adult. It's hard to take him seriously when he's acting like an over emotional 4 year old. EDIT: Jack Kruse is a narcissistic, delusional lunatic. If anyone is a plant I'd say it's him. He says he's fighting against the system and all the things that led to the jab and it's mandates but then behaves in such a way that makes it impossible to take anything he says seriously. It's people like him that allows \"the swamp\" to weaponize the term \"conspiracy theorist\". Whether he's willing to admit it or not the guy is likely going to do far more damage to the cause than good if he doesn't learn how to communicate properly and stop over reacting to every little thing and trying to turn every piece of info into a \"gotchya\" moment. At this point he reminds me more of a MSNBC personality than a doctor.\n",
      "39. Great podcast but I think Jack was a bit out of line calling into question the death of Calleys mother.\n",
      "40. You can mute the entire podcast and release it\n",
      "41. Bobby Kennedy is a MIRACLE! Ok goodbye podcast!!!\n",
      "42. Jack really pisses me off. Terrible, Terrible podcast guest. I keep wanting to turn this off but I want to hear what Cal has to say.\n",
      "43. 13 mins in- Why is the conversation revolving around the most annoying person? He is so slimy. 'Jack, Jack, Jack'\n",
      "44. This Jack guy needs to go. Hold on. Hold on He needs to go!!!\n",
      "45. Jack, Jack, Jack... this could have been a great discussion\n",
      "46. Jack! Thank YOU!Knowledge is Power!Tell It like it is.\n",
      "47. Jack is a medical interrogator ninja and a monster debater. I almost feel sorry for Calle but he spits truth fearlessly and it is like watching an episode of Bully Beatdown without the bully. Just a lad who is driven by cash and obfuscation.\n",
      "48. This is a wild interview for sure. Itâ€™s been a while since I saw the Tucker et al. Podcasts.\n",
      "49. Jack is a FN Rockstar! Dude is a straight shooter. Whether you like him or not\n",
      "50. whether jack is right nor not he just comes off like a giant prick. lmao i had no idea who he is but by the end of the first half i fucking hate that guy.\n",
      "51. 1:46:32 \"Jack, Jack, Jack, ....there might be mind control and we're puppets in a larger plan, but let me be clear on the one point of ignorance vs fraud:  clearly fraud, Jack, Jack, Jack, Jack.  So let me stop you again, Jack...\"   followed by 2:01:26 Blam!\n",
      "52. Thank you, Jack Kruse!\n",
      "53. Yes. I listened and drew my own conclusion...that Jack Kruse is a flipping moron.\n",
      "54. You know right, right ,you know right... like.  Like..hold on,hold on... let me just ,let me just...  hold on hold on ,Jack, Jack...\n",
      "55. Jack is legend!\n",
      "56. jack jack jackjack jack\n",
      "57. What a jerk this Jack  guy is - had to turn it out just a steam of rude insults  - can't make an progree!  Bye bye ...\n",
      "58. This dude said â€œso, so, so, so, soâ€ ever time Uncle Jack called him out.\n",
      "59. jack is shooting himself.  and he discredits himself by sounding so fanatical and paranoid.\n",
      "60. Jack has great bullshit radar,or maybe he was genuinely compartmentalized by his job and didnt question enough..He needs to decide what side of history he is on.At moment im not sure\n",
      "61. These people are Scientologists... It's a cult podcast.\n",
      "62. Jack has a very unpleasant way to talk to people. Very teacher like, charade like. Itâ€™s awful and at the end of it if he wants people to get his points, get to the point and not turning around it to put people down. Itâ€™s really really unbearable to hear him. Iâ€™m in the middle of this podcast and I still donâ€™t understand why they are not agree one another..Time to work together and move forward to fix this untrustworthy country. So childish Jack sorry..\n",
      "63. Jack Jack Jack Jack J-J-J-Jack Jack Jack Jack Jack Jack Jack I'm speaking from the heart Jack Jack Jack Jack Jack Jack Jack Jack Jack Jack Jack Jack Jack Jack Jack Jack Jack Jack Jack\n",
      "64. Jack guy is a complete nut. He is Alex Jones with a medical degree ðŸ˜‚ðŸ˜‚ðŸ˜‚\n",
      "65. I think jack should work next to Mr Kennedy,  I think each should have a staff of there choice,  although Mr Jack should seek the mina ball from the mount as the true medicail symbol makes adjustments global , and yes his knowledge and the way he presents the light in technology and nature is what we need globaly .Light of true god. Dendera.He is deserving of a peice of hey from the bow to the 13 arrows.No bitcoin for me, chit hurts my teeth .\n",
      "66. Iâ€™m telling you I was all in on the CC Means duo until I saw Casey was on a stage with a large group of food and pharmaceutical big wigs.. and I left a comment at the time stating â€¦ â€˜this leaves me very suspicious.. why would she have been invited by this group? And why would she have accepted?â€™I havenâ€™t followed her since.I find Jack very off putting in his rudeness which is unnecessary in order to make a point.. and also in his Big Bang Theory view on life and his own creationâ€¦ but I do think he has a lot worth paying attention to.. regarding sunlight.. even if he doesnâ€™t understand that the source .. the energy from the sun is God.\n",
      "67. Jack is probably one of the worst guests I've ever seen on YouTube\n",
      "68. I am disappointed in Jack Kruse. He is wasting good air time bolstering his inflated ego with bullying.\n",
      "69. Jack is very hard in his questioning when talking about Calleys Mothers death, however, what I will add is that it is easy for Calley to separate himself from the pain and suffering from all the people that have died at the hands of big Pharma\n",
      "70. I really love Dr. Jack Kruse! I admire him so very much. â¤ He calls a  â™ ï¸ a â™ ï¸! Go Jack !!!!! ðŸ˜Š\n",
      "71. Drinking game: take a sip at the mention of Jack\n",
      "72. Dont fuck with bad santa Jack ðŸ˜…\n",
      "73. Jack Jack\n",
      "74. Havenâ€™t watched Jack before so canâ€™t speak to his platform. The things he advocates for in a cursory search arenâ€™t wrong. But Calley and Casey advocating for food and pharma improvements arenâ€™t wrong either.Whether you like the way Calley answers or not, I am just as put off by Jack in this particular interview.It came off to me as an â€œIâ€™m an ego maniac that needs everyone to know Iâ€™m a physician and Iâ€™m jealous that you and your sister came on scene and sold more books than me this year.â€I get the connections Jack has made in Calleys history. But Calley has said upfront that he was a lobbyist. So connections to those elites isnâ€™t a surprise. Either way, no one knows your body like you so do your own research and do not eat or take what is not beneficial to you, the individual.Sad, but until changes are employed, this is what our â€œhealthcareâ€ has becomeâ€¦\n",
      "75. Jack gets A* for doing his homework!!!\n",
      "76. Ummm heâ€™s talked about his background.  This was not a gotcha Jack lol.  Nuts\n",
      "77. Jack...Jack....Jack...Jack....what a creepy dude.\n",
      "78. Jack should start a journalism school\n",
      "79. Hardest episode to listen too.Jack came on way to strong, never had an open dialog.Literally great topic, super hard to stay tuned. But I did....\n",
      "80. Jack seems to be lying. 1:06:05 1:06:06\n",
      "81. Jack, Jack, Jackâ€¦GAAAAAY!\n",
      "82. Oh boy! Let me make popcorn this is gonna be good!\n",
      "83. I left this with a completely different view of the Means.  I can't help but think he's pushing propaganda.  Thank you Danny Jones for this discussion.  We need more Dr. Jacks out there.\n",
      "84. Americans side with Jack!\n",
      "85. Jack for president 2028!!!\n",
      "86. They mentioned an episode with someone from the human genome project and the episode was oulled, which episode was that and is it avail on Spotify/patreon?\n",
      "87. Let's just say it. Jack may be incredibly informed, but he is also an A-hole with arrogance that can hardly be overstated. He reminds me of Trump in the first presidency when he spewed so much crap about so many things.  He sees conspiracies everywhere. He makes huge assumptions without any real evidence to support things.\n",
      "88. Jack couldn't break through the impregnable phony barrier, but it was a good effort.\n",
      "89. This  Means guy canâ€™t answer a single fking question Jack is asking. The second Jack talks casey becomes the tone police. Casey is so clearly giving b.s. answers while Jack is literally just talking from the heart. Jack is clearly just pursuing truth & the fact that casey is sh*ting his pants the whole time tells us everything we need to know. I donâ€™t trust this guy far as I can throw him. Dude just lost ALL credibility. Yes I watched every minute of the podcast. Great job letting them talk Danny, even though I think your annoying. You host a good podcast.\n",
      "90. Heâ€™s working too hard to defend himself and dancing around EVERY question. Heâ€™s definitely a plant, IMO.  thousands have been screaming his message for years and donâ€™t get the press the Means have in the last 6 months. Fishy for sure!! Love this Uncle Jack!! Youâ€™re never wrong!! He underestimated what he was walking into ! I love it!!!! We need Dr. Jack to head up the MAGA movement. Iâ€™d rather have him than RFJ Jr\n",
      "91. Jack, Jack, Jack, Jack, Jack.\n",
      "92. The way he keeps saying â€œJackâ€ is so condescending and on purpose. Called is being exposed for what he is.\n",
      "93. How do we see the referenced Kieran interview or however you spell his name\n",
      "94. Take a shot for every \"jack, jack, jack\"\n",
      "95. Dr Jack is 100% correct, Carlson and Rogan are deep stare fakes!!!  This is one of the very very few individuals I can get fully behind. The rest, youâ€™ll need to earn my trust.  Dr Jack has my trust which puts him in about 1 in 1 billon.\n",
      "96. Was he just returning video tapes?\n",
      "97. This guy sounds sleezy as hell. I thought \"Jack\" was spoken too much in Titanic .. this dude sounds like Rose\n",
      "98. Danny Jones, I think you could improve your ability to moderate your podcasts.  Jack, in his usual fashion - had to monopolize the â€œconversationâ€ and was completely belligerent.   Not sure why Calley actually remained and continued to put up with his conspiracy theories.   The questions pertaining to the death of his mother were completely inappropriate, disrespectful and shameful.\n",
      "99. Jack Jack Jack Jack.. why are you being so mean? Iâ€™m just trying to bring about a new paradigm to science. To globalize healthcare, and to bring about a new world order.\n",
      "100. Jack is preposterous.\n",
      "101. Jack cooked this clown; he gets so defensive and tries to talk his way out of questions he doesnâ€™t want to answer.\n",
      "102. Jack reminds me of Cernovich. Very smart and provide tons of useful stuff. ANNOYING af know it allâ€™s. He knows everything and any answer is not good enough. Ask the question and shut the fuck up and let people answer. We need to hear the answers.Rogan is part of the global elite? Tucker is part of the problem? What an idiot.\n",
      "103. I think Jack may legitimately be a narcissist. He constantly seeks praise and tries to destroy anyone who takes the spotlight away from him, even if for a moment.\n",
      "104. Jack talks about what we did to the kraut ms and what we did to the Japs but he doesn't realize that what he's talking about what the Yankees are going to be doing to the Yankees.  Having said that I agree that he a doctor should be sent to Guantanamo. Maybe we'll let Mary get a pass on  good behavior but definitely not him because he hasn't done Jack shit.  All he did was retire. And then 2 days a week volunteer .  He nevter achieved his goals and he went to a s*** school so now he's trying to s*** on everyone else. What they used to say in the 60s is that guy's got to get laid but he's NOT going to get laid because no b** , even the former jewish head of our federal health agency  would consent.  .\n",
      "105. I donâ€™t think Jack has hate in his heart, itâ€™s called righteous  anger.\n",
      "106. I have a hard time with people like Jack. You can be totally right but such an emotional aggressive asshole it totally takes away from the point. I see both sides and think thereâ€™s a lot of good to take away from this pod. I just rather enjoy a debate when both sides are respectful.\n",
      "107. Hi, yes, can someone please get uncle jack on trumps team? that would make my 2025 the BEST, thanks.\n",
      "108. I just tried to find Dr Jack Kruse on the web to see what school he is so not famous that he's not on the web &  obviously did not go to Harvard or Stanford or he wouldn't be dissing them. I did find a doctor Jack Kruse who solved his health problem by food and he wrote a whole book on it and created a diet to help Americans change their s*** way of eating so maybe he's jealous of that Jack Kruse  as well as this young man but I'm sick of old men being jealous and either sending out young man to die in war or beating them up in person on the web. I'm glad some of you say Dr Jack helped you but right now he is presenting himself as a Doctor Jekyll Dr Hyde.\n",
      "109. This is ridiculous.Calley & Casey Means walked out of their respective careers because their eyes were opened to the devastating effects of pharma/food on their mother.  THEIR MOTHER. If they were weaker, less intelligent, less driven individuals (clearly inherited/taught - in part- by the same mother) they wouldn't have walked away from the env'ts that caused her chronic disease and death. The timing of their efforts was perfect for gaining awareness & coincided with (likely) the biggest mass-awakening in US history. Tucker then opened the floodgates when he interviewed Calley.People who have been insiders & then had awakenings are exactly the people you should WANT on your side.  They are whistleblowers.Who makes the best doctors? The ones who've woken up to the corruption & limitations of their own training in allopathic medicine, and retrain in functional med. This is EXACTLY what Casey Means is, and Calley is her analog from the PR/marketing world.Jack's incessant unhinged & ludicrously conspiratorial attack just makes him look hysterical.Mary's rage after her treatment at the hands of Houston Methodist and the TX medical board is completely understandable, but pointing fingers at Calley because he happened to have effectively the same awakening as her but has been more successful smacks of envy.\n",
      "110. \"We should burn it down.\"... while i agree with the sentiment and think there needs to be accountability amd criminal charges brought, that is the most reductive and reactionary solution possible.  I understand why Jack is so angry, but he's let all that emotion turn him into a petulant child.\n",
      "111. For those of us who missed the Kevin McKinnon interview that was taken down-how can we find it?\n",
      "112. Jack does more damage to his cause than any of the ppl or entities he \"hates.\"   ...I actually agree with everything he's saying, but his personality and obvious bad faith behavior make him intellectually revolting (he's sloppy looking too, but that's besides the point).   I wouldn't go so far as to say he's an industry plant tasked with pushing ppl away from looking at the things he talks about, but I honestly wouldn't be very surprised if he was.   He's prob just been isolated and cooped up too long in his own correlation  bubble.\n",
      "113. I read a few more comments and I would say if they want to say Dr Jack has balls,  let's see him attack the President. Trump will make mince meat out of him. I would love to see it though.\n",
      "114. I just got an email, I can't reply to, telling me how if I want to hear your show, I can pay for the privilege. Sorry I just don't think you're that special, which is why I am unsubscribing!And go to hell patreon ðŸ‘¿\n",
      "115. Dr jack has the veil threat when he talks about Casey and the fact she does not have a medical license and he doesn't say the silent part which is that she's practicing medicine and he doesn't say it because she's not practicing medicine she never said that eating an egg instead of fruit loops would cure you of anything I've been through this a million times because I belong to alternative health entities decades before Dr Jack ever got on this mRNA bandwagon which she's ready to hell and back. You can't say it cures but you can say it makes you feel better etcetera etcetera. The veil threat shows that guy is evil and I'm glad if he's helping people medically speaking because evil always as he can tell you right now surrounds itself with good and that's what he's trying to say that Kelly who is a very naive young man is doing but I can see he's not doing that he's not as clever as evil Jack because when you make a an agreement with the devil he gives you he does give you certain high-level means to function and to achieve your goal and it's very sad that Dr Jack is a doctor because he has his evil streak which is so obvious if you've ever been around evil you know it.\n",
      "116. It's pretty interesting _ the comments are even more interesting but I don't understand why people can't be  Christian. A Christian -- as opposed to a Jew or a Muslim or an atheist which is probably what Jack is-- xtan & does  forgive. This guy Callie definitely was on the side of darkness and he still has a lot of the mannerisms of those people and that's not  debatable  but the fact of the matter is he chose to be on the side of light due to his sister's influence and I don't think that it should be held against him that once he was in darkness but now he no longer is. Dr Jack is in darkness in his own way because he interrogates as if he is the Romans nailing Christ to the cross. I'm not impressed with Jack the interrogator and the screaming Mary.\n",
      "117. Dr. Jack Kruse needs to be on your POD cast a lot more.\n",
      "118. This guy has no idea about love well done jack pulling this guy apart\n",
      "119. Jack, jack, jack, jackâ€¦. Hold on, hold on, hold on ðŸ˜‚\n",
      "120. The prophet jack â¤â¤The man is a legend ðŸ˜‡\n",
      "121. Jacks entire goal is truth, truth is what is so needed today.\n",
      "122. Love Uncle Jack and I totally smell something fishy with this guy and his family and work history. Heâ€™s got connections and that means he owe someone or many favors!! GO JACK GO!!!!\n",
      "123. To all those looking for the full Kevin McKernan interview it is not on screw tube! I was able to listen to it on my podcast app, if you made it through this one, it's 2 1/2 hours and it'll be a lot easier. No bloodbath, but the blood shed we saw here was thoroughly necessary. Thank you to all.P.S. Oz is the WEF\n",
      "124. Gaetz got a facelift Jack there's a problem there.\n",
      "125. If jack is involved with matt gaetz....... the pervert, i automatically can say that he is also a high ranking pervert. Birds of a feather flock together\n",
      "126. Rogan will have Jack, for sure\n",
      "127. Jack is a very intelligent man. Calley is a totally different person compared to the podcast on Tucker & Rogan\n",
      "128. Jack is basically a tyrant. His word is law to him in a manner of speaking. The guy is totally impossible to talk to. No matter how educated he is a complete idiot. Does nothing but totally assault anyone that doesnt have his exact same opinion. Dud is a moron\n",
      "129. If Jack were a detective his interrogation would be thrown out of court.\n",
      "130. Jack your being menacing. He says as if he shouldnt be.\n",
      "131. I am 1000 % backing the man jack . I got the glasses from listen to the last one thanks\n",
      "132. jack, jack, jack, jack, jackcan't stop the kruse missile\n",
      "133. The most annoying thing about this D stick is him repeating, jack, jack, jack. Itâ€™s condescending and weak. Especially because he doesnâ€™t say anything and skirts any threatening discourse. This guy is greasy.\n",
      "134. Kind of see why Dr Kruse is having so much trouble getting attention and convincing people of anything. Being an asshole is a relatively easy sport, you don't get attention by being good at it. What an insufferable quack.\n",
      "135. Every time he said â€œJack, Jack, Jackâ€ I pictured the ineffectual mayor from â€œNightmare Before Christmasâ€\n",
      "136. Jack is very off putting.\n",
      "137. One issue I take with jack is his uncontrolled intensity. He's always ready to connect the next dot, maybe even when there's no need to draw a connection between two stand alone issues. I've got no doubts that jack is intelligent and has done the legwork himself to bring himself to the current version of himself that has been convinced he's 100% correct in all things plastered on his spiral. It's hard to watch with accusations such as the guy's dad's book and a few other points similar to. At the end of all this there is room for cohesive direction and I just don't think jack will be an instrument in making progress in the mainstream. He's better left as the resource and research guy, imho. He's too abrasive due to his overly passionate emotions tied to his beliefs. Fact or not, it comes across as some alex jones style 'retraining camp' guest speaker\n",
      "138. I don't understand how so many believe Jack's demeanor and relational style were helpful to the conversation! I think he was hostile, judgmental and asked questions that were very controlling and manipulative. My opinion of him was significantly diminished listening to this podcast.\n",
      "139. Jack IS bad faith.\n",
      "140. Jack Jack Jack he says saying Jack sh1t !!Heâ€™s not ignorant.. heâ€™s a good student of Fabian society.\n",
      "141. How is anyone ever able to have a conversation with Jack. He allows very little dialog. And he seems to be able to link every thing to the darkness of ~Ã—~. Yet no one is able to expose evil without being close to it. Its the hardest thing in the world to clean a lagoon and not get shit on yourself.\n",
      "142. Jack is such an ass, i don't want to listen\n",
      "143. That jack guy is deranged.\n",
      "144. I think Jack would accomplish alot more if he weren't so confrontational.\n",
      "145. \"Jack, Jack, Jack....\"\n",
      "146. Jack jack jack jack jack jack jack stop jack\n",
      "147. Jack Jack Jack ,Iâ€™m jacked off by this guy repeating JACK.\n",
      "148. I think what Jack is trying to say is answer the damn call to service Jonah before you get thrown overboard and get swallowed by a whale and taken to hell for three days like Jordan Peterson said.\n",
      "149. I think what Jack is trying to say is answer the damn call to service Jonah before you get thrown overboard and get swallowed by a whale and taken to hell for three days like Jordan Peterson said.\n",
      "150. I know Jack said he wouldnâ€™t go on JRE, but that is self sacrifice I think he should reconsider if he truly wants to get his word heard\n",
      "151. From an evaluation of emotional tone, Jack is very antagonistic...\n",
      "152. \"I think you're full is of  s h ! t.\"   Thank you.  Thank you.  Thank you Jack Cruse.\n",
      "153. The fact that he doesnâ€™t ask about more info when they start talking about Kevin, shows how much heâ€™s front\n",
      "154. â€œJack Jack Jack Jack Jack Jack Jack Jack Jackâ€¦â€¦â€¦why are you being mean to me?â€\n",
      "155. Hold onâ€¦.hold onâ€¦.lolSo choppy\n",
      "156. Yeah if he knew who he was really working for that is a moral compromise for evil, not against it. Thank you Dr. Jack for your diligent truths and exposing the fruits of labor this man produces!\n",
      "157. Jack is insufferable.\n",
      "158. I'm a fan of Jack, but he does have a condescending way of debating.  He comes off as \"I know all the answers before you answer my question\".\n",
      "159. Jack is the real deal â¤\n",
      "160. I agree with Jack Krus  about tte fronting\n",
      "161. Jack Krause is a hypocritically ass. He claims he REFUSES to go on Rogan, Tucker, etc because they are all bought - but somehow demands ppl listen to him by proxy by beating on a junior level lobbyist. If he wasnâ€™t a bully- heâ€™d have gotten to the table and likely been heard. Heâ€™s smart- but what a dumb tactic.\n",
      "162. If you are also unaware of the atrocities that occurred during the pandemic and the dangers of the mRNA shots. Please do yourself the service of watching the new documentary, â€˜Thank You Dr. Fauciâ€™. It is now streaming on the Tucker Carlson network- you may see that perhaps  Jackâ€™s temperament is justified.\n",
      "163. This Dr Jack may be knowledgeable but wow us he a JACK-ASS!!Is it any wonder heâ€™s NOT asked to be on decisive policy changing committees of substance for change??Shoot- NONE OF US normal folk (majority of US or World population) knew ANY of these conspiracy things 4 years ago. For these Drs to attack Calley this way proves we will never get ANYWHERE with such an approach. I also think itâ€™s ironic he shows up with a flipping orange Bitcoin Santa hat as a billboard  selling coins. What a shame heâ€™s a Pompous Ass that had he played this conversation differently- heâ€™d likely garnered a seat at the table. Jack may do well to put the chip bag down himself and read the book How To Win Friends and Influence People. Is love to see its resume of work and cohorts to start connecting dots straight to BlackRock, State Street and Vanguard. My point- WE ALL ARE IN THE MATRIX and most of us just starting to truly understand how. Iâ€™m still team Calley after this demonstration. Dr Jack Ass will NEVER make any policy board moving fwd. ðŸ¤¦ðŸ»â€â™€ï¸\n",
      "164. I couldnâ€™t help but think Iâ€™d seen Jack before but couldnâ€™t place where. Then it occurred to me, heâ€™s very like Penn Jillet in his speaking and even looks a bit like him.BTW spotify has the unedited version if it really bothers anyone\n",
      "165. 25 minutes into this and Jack is being a real jackhole!\n",
      "166. Jack.....Jack.....jack..jack.Jack!    U BROKE ME!  HAHHAHAHA\n",
      "167. UGH....first time watching this podcast so I do not know who these people are but holy hell Jack needs to take a few breaks and STOP being RUDE!!!! Don't care who you are or what you know.....maybe take your passion somewhere else dude!\n",
      "168. Is the kevin Mckernan episode available on patreon or anywhere else?\n",
      "169. Hes a cfr shill to try to keep the institutions that we want to dismantle stay in tact. Jack sussed it out 30 min mark\n",
      "170. Ole uncle Jack. The Kruse missile. He's fired up, should be home exactly how everyone else feels.\n",
      "171. I listened to this on the podcast â€¦ I 100 percent agree with jack!!!! This other man is very illusive and I can tell he is completely connected to the dark side of this !!! He is afraid to lose the money he is on the take for â€¦\n",
      "172. Jack, for the love. You say you have not said the word conspiracy, but you think this guy is part of a conspiracy, and then you pretend like you don't think there is a conspiracy, but you think there is a conspiracy. Just clearly state your points. CLEARLY.\n",
      "173. As much as Iâ€™m on jacks side he gives people a bad rep when he canâ€™t shut up and let the man speak\n",
      "174. I'm so sick of the means boy using the name Jack, Jack Jack Jack... I am 15 minutes into this interview and I don't trust the means boy. lol\n",
      "175. Jack. Jack. JACKKKKKKKK JACK. jaaaaaaaackkkkkkkk\n",
      "176. Jihad ðŸ˜‚ this idiot couldn't answer a single question from Jack\n",
      "177. Jack...jack....jack....jack ðŸ˜‚\n",
      "178. The more I listen to Jack Cruse the more I just get frustrated with his inability to listen, and his lack of ability to connect with his heart. We all believe in his ideas to some extent, but his bullying and bulldozing approach is offputting to say the least. How he handled addressing Callieâ€˜s mom dying is just uncalled for and I lost a lot of respect for him. It shows his lack of compassion.\n",
      "179. Jack is a hypocrite it's clear as the sun in the sky\n",
      "180. This does seem adversarial, but thatâ€™s whatâ€™s missing in hard conversations now days.  Tell a PR man like Calley not to sing and dance around hard questions; theyâ€™re trained to stay in the middle of the road to not alienate people.  More people need to look into Jack, he brings some frightening  revelations about our modern medical society and what itâ€™s based on and what it came from.  Itâ€™s unsettling in the highest sense.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def show_topic_full(topic_id, labels_dict):\n",
    "    print(f\"=== Topic {topic_id} ===\\n\")\n",
    "    \n",
    "\n",
    "    for model_name, model_labels in labels_dict.items():\n",
    "        labels = model_labels.get(topic_id, [])\n",
    "        print(f\"--- {model_name} Labels ---\")\n",
    "        print(\", \".join(labels) if labels else \"No labels\")\n",
    "        print()\n",
    "    \n",
    "\n",
    "    print(f\"--- All Texts in Topic {topic_id} ---\")\n",
    "    texts_in_topic = [text for text, t in zip(texts, topics) if t == topic_id]\n",
    "    \n",
    "    if not texts_in_topic:\n",
    "        print(\"No texts found for this topic.\")\n",
    "    else:\n",
    "        for i, text in enumerate(texts_in_topic, 1):\n",
    "            print(f\"{i}. {text}\")\n",
    "\n",
    "\n",
    "random_topic = random.choice(list(set(topics) - {-1}))\n",
    "show_topic_full(random_topic, labels_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automated Evaluation with Gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since collecting human judgments for a large number of topics and comments is impractical given our resources, we employ Google Gemini as an automated evaluator. This allows us to approximate human-like assessment of label quality without the need for extensive manual annotation.\n",
    "\n",
    "\n",
    "For every topic, Gemini is provided with:\n",
    "1. The labels generated by each labeling method (BERTopic, KeyBERT, and Gemini itself).\n",
    "2. A sample of comments belonging to the topic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gemini Numerical Evaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gemini is asked to act as an impartial evaluator and assign a score from 1 to 100 for each set of labels, focusing on:\n",
    "- **Clarity** â€” Are the labels understandable and well-phrased?\n",
    "- **Relevance** â€” Do the labels reflect the topic's content?\n",
    "- **Descriptiveness** â€” How well do the labels summarize the topic?\n",
    "\n",
    "The function collects the individual topic scores and computes the **average rating** for each labeling method across all topics.\n",
    "\n",
    "While this does not fully replace human evaluation, using a powerful LLM helps us approximate human judgment at scale and provides valuable insights into the relative performance of each labeling method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Evaluating Topic 0...\n",
      " Evaluating Topic 1...\n",
      " Evaluating Topic 2...\n",
      " Evaluating Topic 3...\n",
      " Evaluating Topic 4...\n",
      " Evaluating Topic 5...\n",
      " Evaluating Topic 6...\n",
      " Evaluating Topic 7...\n",
      " Evaluating Topic 8...\n",
      " Evaluating Topic 9...\n",
      " Evaluating Topic 10...\n",
      " Evaluating Topic 11...\n",
      " Evaluating Topic 12...\n",
      " Evaluating Topic 13...\n",
      " Evaluating Topic 14...\n",
      "\n",
      "=== Average Scores ===\n",
      "BERTopic: 56.33/100\n",
      "KeyBERT: 57.33/100\n",
      "Gemini: 79.0/100\n"
     ]
    }
   ],
   "source": [
    "def evaluate_all_topics_with_gemini(labels_dict, model):\n",
    "    results = {name: [] for name in labels_dict.keys()}\n",
    "\n",
    "    all_topics = list(set(topics) - {-1})\n",
    "    \n",
    "    for topic_id in all_topics:\n",
    "        print(f\" Evaluating Topic {topic_id}...\")\n",
    "\n",
    "        prompt = f\"Evaluate the labeling quality for Topic {topic_id}.\\n\"\n",
    "        prompt += \"For each model, here are the labels it generated:\\n\\n\"\n",
    "\n",
    "        for model_name, model_labels in labels_dict.items():\n",
    "            labels = model_labels.get(topic_id, [])\n",
    "            prompt += f\"--- {model_name} Labels ---\\n\"\n",
    "            prompt += \", \".join(labels) if labels else \"No labels\"\n",
    "            prompt += \"\\n\\n\"\n",
    "\n",
    "        prompt += \"--- Example Texts in this Topic ---\\n\"\n",
    "        texts_in_topic = [text for text, t in zip(texts, topics) if t == topic_id]\n",
    "        \n",
    "        for i, text in enumerate(texts_in_topic, 1):\n",
    "            prompt += f\"{i}. {text}\\n\"\n",
    "\n",
    "        prompt += (\"\\n\\nPlease rate each model from 1 to 100, based on how well the labels describe the topic and make sense.\\n\"\n",
    "                   \"Imagine you are a professional linguist and data scientist who was not involved in generating these labels.\\n\"\n",
    "                   \"Your task is to objectively evaluate each set of labels without any consideration of their source. Focus only on clarity, relevance, and how well the labels describe the topic's content.\\n\"\n",
    "                   \"Give only numeric ratings like this:\\n\"\n",
    "                   \"- BERTopic: <score>\\n\"\n",
    "                   \"- KeyBERT: <score>\\n\"\n",
    "                   \"- Gemini: <score>\\n\")\n",
    "\n",
    "        chat = model.start_chat()\n",
    "        response = chat.send_message(prompt)\n",
    "\n",
    "        for model_name in results.keys():\n",
    "            try:\n",
    "                line = [line for line in response.text.splitlines() if model_name in line][0]\n",
    "                score = int(''.join(filter(str.isdigit, line)))\n",
    "                results[model_name].append(score)\n",
    "            except Exception as e:\n",
    "                print(f\" Failed to extract score for {model_name} in Topic {topic_id}: {e}\")\n",
    "\n",
    "    avg_scores = {model: round(np.mean(scores), 2) if scores else 0 for model, scores in results.items()}\n",
    "\n",
    "    print(\"\\n=== Average Scores ===\")\n",
    "    for model, score in avg_scores.items():\n",
    "        print(f\"{model}: {score}/100\")\n",
    "\n",
    "    return avg_scores\n",
    "\n",
    "avg_scores = evaluate_all_topics_with_gemini(labels_dict, gemini_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gemini Text Explainer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complement the numerical evaluation, we use Gemini to provide short explanations for the average scores of each labeling method. The `explain_scores_with_gemini` function prompts Gemini to justify the given scores by commenting on aspects such as clarity, relevance, and interpretability of the generated labels.\n",
    "\n",
    "This step helps us gain qualitative insights into the strengths and weaknesses of each method, beyond just numerical ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Raw Gemini Response ===\n",
      "BERTopic: 56.33/100\n",
      "Explanation: BERTopic might have received a lower score because its labels, while potentially reflecting underlying topics, could lack clarity or be too broad, hindering easy interpretation.\n",
      "\n",
      "KeyBERT: 57.33/100\n",
      "Explanation: KeyBERT's score suggests its labels were moderately useful. They likely extracted relevant keywords, but the labels might have lacked sufficient context, making them less interpretable than a more refined topic modeling approach.\n",
      "\n",
      "Gemini: 79.0/100\n",
      "Explanation: Gemini's higher score indicates its labels were generally of high quality. They were likely clear, relevant, and interpretable, indicating a strong understanding of the input data and a good ability to summarize or generate meaningful labels.\n",
      "\n",
      "=== Explanations ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Average Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BERTopic</td>\n",
       "      <td>56.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KeyBERT</td>\n",
       "      <td>57.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gemini</td>\n",
       "      <td>79.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Average Score\n",
       "0  BERTopic          56.33\n",
       "1   KeyBERT          57.33\n",
       "2    Gemini          79.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def explain_scores_with_gemini(avg_scores, model):\n",
    "    # Prompt\n",
    "    prompt = \"You are an objective evaluator.\\n\"\n",
    "    prompt += \"Please explain briefly for each model why it might have achieved its respective average score.\\n\"\n",
    "    prompt += \"Focus on label quality (clarity, relevance, interpretability).\\n\"\n",
    "    prompt += \"Respond with lines in the following format:\\n\"\n",
    "    prompt += \"<Model>: <score>/100\\nExplanation: <short explanation>\\n\\n\"\n",
    "\n",
    "    for model_name, score in avg_scores.items():\n",
    "        prompt += f\"{model_name}: {score}/100\\n\"\n",
    "\n",
    "    # Gemini call\n",
    "    chat = model.start_chat()\n",
    "    response = chat.send_message(prompt)\n",
    "\n",
    "    print(\"=== Raw Gemini Response ===\")\n",
    "    print(response.text)\n",
    "\n",
    "    # More robust extraction\n",
    "    explanation_dict = {}\n",
    "    lines = response.text.splitlines()\n",
    "    current_model = None\n",
    "\n",
    "    for line in lines:\n",
    "        for model_name in avg_scores.keys():\n",
    "            if model_name in line and ':' in line:\n",
    "                current_model = model_name\n",
    "                break\n",
    "\n",
    "        if current_model and \"Explanation\" in line:\n",
    "            explanation = line.split(\"Explanation:\")[-1].strip()\n",
    "            explanation_dict[current_model] = explanation\n",
    "            current_model = None\n",
    "\n",
    "    # fallback\n",
    "    for model in avg_scores.keys():\n",
    "        if model not in explanation_dict:\n",
    "            explanation_dict[model] = \"Missing\"\n",
    "\n",
    "    # DF\n",
    "    df = pd.DataFrame([\n",
    "        {\"Model\": model, \"Average Score\": avg_scores[model]}\n",
    "        for model in avg_scores.keys()\n",
    "    ])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# --- Usage ---\n",
    "explanation_df = explain_scores_with_gemini(avg_scores, gemini_model)\n",
    "\n",
    "print(\"=== Explanations ===\")\n",
    "display(explanation_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Purity Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To assess the internal consistency and relevance of the generated labels, we define a custom **Cluster Purity** metric.\n",
    "\n",
    "For each topic, the dominant keyword is selected as the most frequent label suggested by the model. Then, we compute the proportion of comments within the topic that actually contain this dominant keyword.\n",
    "\n",
    "Formally:\n",
    "- A purity score of 1.0 means that all comments in the topic contain the dominant keyword.\n",
    "- A lower score indicates that fewer comments explicitly mention the dominant keyword.\n",
    "\n",
    "The final purity reported for each model is the average purity across all topics.\n",
    "\n",
    "This metric provides a simple but insightful way to measure how well the model-generated labels are grounded in the actual content of the comments. However, it is important to note that purity does not capture the full semantic alignment between labels and topics â€” it only measures **surface-level keyword occurrence**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Average Purity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BERTopic</td>\n",
       "      <td>0.766912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KeyBERT</td>\n",
       "      <td>0.582433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gemini</td>\n",
       "      <td>0.492755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Average Purity\n",
       "0  BERTopic        0.766912\n",
       "1   KeyBERT        0.582433\n",
       "2    Gemini        0.492755"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize(text: str) -> set:\n",
    "    return set(re.findall(r'\\w+', text.lower()))\n",
    "\n",
    "\n",
    "def compute_cluster_purity(\n",
    "    texts: Sequence[str],\n",
    "    topics: Sequence[int],\n",
    "    labels_dict: Dict[str, Dict[int, List[str]]],\n",
    "    ) -> pd.DataFrame:\n",
    "    purities = []\n",
    "\n",
    "    for model_name, model_labels in labels_dict.items():\n",
    "        model_purities = []\n",
    "\n",
    "        for topic_id, keywords in model_labels.items():\n",
    "            texts_in_topic = [text for text, t in zip(texts, topics) if t == topic_id]\n",
    "\n",
    "            if not texts_in_topic or not keywords:\n",
    "                model_purities.append(0.0)\n",
    "                continue\n",
    "\n",
    "            match_count = 0\n",
    "\n",
    "            match_count = sum(\n",
    "                    1 for text in texts_in_topic\n",
    "                    if any(tokenize(kw) & tokenize(text) for kw in keywords)\n",
    "                )\n",
    "\n",
    "            purity = match_count / len(texts_in_topic)\n",
    "            model_purities.append(purity)\n",
    "\n",
    "        purities.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Average Purity\": np.mean(model_purities)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(purities)\n",
    "\n",
    "purity_df = compute_cluster_purity(texts, topics, labels_dict)\n",
    "display(purity_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster Purity (with Caution)\n",
    "Note: We include the Cluster Purity metric as a lightweight, surface-level measure of consistency between topic labels and their corresponding texts. It computes the proportion of comments in a topic that contain (even partially) the assigned keywords.\n",
    "\n",
    "However, this metric is highly limited:\n",
    "\n",
    "It does not account for semantic similarity or paraphrasing.\n",
    "\n",
    "It may penalize high-quality, abstract labels that donâ€™t explicitly appear in the raw text.\n",
    "\n",
    "It can produce misleadingly low scores for otherwise accurate labels.\n",
    "\n",
    "Interpretation guidance:\n",
    "We consider purity scores only as a sanity check, with very low weight in our overall evaluation. High purity might indicate strong surface alignment, but low purity does not necessarily mean the label is bad.\n",
    "\n",
    "To evaluate labeling quality more meaningfully, we rely primarily on semantic-based methods (e.g., embedding similarity, human inspection, or external tasks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "fake = Faker()\n",
    "\n",
    "def perturb_texts(texts, p_insert=0.3, p_delete=0.2, p_shuffle=0.2):\n",
    "    perturbed_texts = []\n",
    "\n",
    "    for text in texts:\n",
    "        words = text.split()\n",
    "\n",
    "        if len(words) > 0 and random.random() < p_insert:\n",
    "            idx = random.randint(0, len(words) - 1)\n",
    "            words.insert(idx, fake.word())\n",
    "\n",
    "        if len(words) > 3 and random.random() < p_delete:\n",
    "            idx = random.randint(0, len(words) - 1)\n",
    "            del words[idx]\n",
    "\n",
    "        if len(words) > 4 and random.random() < p_shuffle:\n",
    "            idx1, idx2 = random.sample(range(len(words)), 2)\n",
    "            words[idx1], words[idx2] = words[idx2], words[idx1]\n",
    "\n",
    "        perturbed_texts.append(\" \".join(words))\n",
    "\n",
    "    return perturbed_texts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "perturb_texts â€” Text Augmentation with Faker\n",
    "This function introduces light random perturbations to a list of input texts by inserting a synthetic (fake) word into each sentence. It's useful for:\n",
    "\n",
    "Testing model robustness to noisy or altered input.\n",
    "\n",
    "Augmenting datasets with slight textual variations.\n",
    "\n",
    "Simulating user-generated content or natural language variation.\n",
    "\n",
    "How it works:\n",
    "For each input text, it randomly selects a position in the word list.\n",
    "\n",
    "It generates a fake word using the Faker library.\n",
    "\n",
    "The fake word is inserted into the chosen position in the sentence.\n",
    "\n",
    "The perturbed version is added to a new list of texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_topics(labels1, labels2):\n",
    "    matching = {}\n",
    "    for topic1_id, topic1_labels in labels1.items():\n",
    "        best_match = None\n",
    "        best_score = -1\n",
    "        set1 = set([label.lower() for label in topic1_labels])\n",
    "        \n",
    "        for topic2_id, topic2_labels in labels2.items():\n",
    "            set2 = set([label.lower() for label in topic2_labels])\n",
    "            if len(set1) == 0 or len(set2) == 0:\n",
    "                continue\n",
    "            score = len(set1 & set2) / len(set1 | set2)  # Jaccard\n",
    "            \n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_match = topic2_id\n",
    "                \n",
    "        matching[topic1_id] = (best_match, best_score)\n",
    "    return matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_stability_with_matching(labels_dict_run1, labels_dict_run2):\n",
    "    stability_results = []\n",
    "\n",
    "    for model_name in labels_dict_run1.keys():\n",
    "        labels1 = labels_dict_run1[model_name]\n",
    "        labels2 = labels_dict_run2[model_name]\n",
    "\n",
    "        matching = match_topics(labels1, labels2)\n",
    "\n",
    "        topic_stabilities = []\n",
    "        for topic1_id, (topic2_id, _) in matching.items():\n",
    "            if topic2_id is None:\n",
    "                stability = 0.0\n",
    "            else:\n",
    "                set1 = set([label.lower() for label in labels1[topic1_id]])\n",
    "                set2 = set([label.lower() for label in labels2[topic2_id]])\n",
    "                if len(set1) == 0 and len(set2) == 0:\n",
    "                    stability = 1.0\n",
    "                elif len(set1) == 0 or len(set2) == 0:\n",
    "                    stability = 0.0\n",
    "                else:\n",
    "                    stability = len(set1 & set2) / len(set1 | set2)  # Jaccard\n",
    "            topic_stabilities.append(stability)\n",
    "\n",
    "        avg_stability = np.mean(topic_stabilities)\n",
    "        stability_results.append({\n",
    "            \"Model\": model_name,\n",
    "            \"Average Matched Stability\": round(avg_stability, 3)\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(stability_results)\n",
    "\n",
    "# perturb the dataset\n",
    "perturbed_texts = perturb_texts(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturbed_topics, perturbed_probs = topic_model.fit_transform(perturbed_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_labeler = TopicLabeler(perturbed_texts, perturbed_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_bertopic_labels = second_labeler.label_with_bertopic(topic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_keybert_labels = second_labeler.label_with_keybert(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_gemini_labels = second_labeler.label_with_gemini(gemini_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Average Matched Stability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BERTopic</td>\n",
       "      <td>0.108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KeyBERT</td>\n",
       "      <td>0.166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gemini</td>\n",
       "      <td>0.169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Average Matched Stability\n",
       "0  BERTopic                      0.108\n",
       "1   KeyBERT                      0.166\n",
       "2    Gemini                      0.169"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "second_labels_dict = {\"BERTopic\": second_bertopic_labels, \"KeyBERT\": second_keybert_labels, \"Gemini\": second_gemini_labels}\n",
    "stability_df = compute_stability_with_matching(labels_dict, second_labels_dict)\n",
    "display(stability_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Final Model Ranking (with Gemini normalized properly) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Average Purity</th>\n",
       "      <th>Stability</th>\n",
       "      <th>Gemini Normalized</th>\n",
       "      <th>Final Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gemini</td>\n",
       "      <td>0.492755</td>\n",
       "      <td>0.169</td>\n",
       "      <td>0.7900</td>\n",
       "      <td>69.817553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BERTopic</td>\n",
       "      <td>0.766912</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.5633</td>\n",
       "      <td>53.813119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KeyBERT</td>\n",
       "      <td>0.582433</td>\n",
       "      <td>0.166</td>\n",
       "      <td>0.5733</td>\n",
       "      <td>53.348328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Average Purity  Stability  Gemini Normalized  Final Score\n",
       "2    Gemini        0.492755      0.169             0.7900    69.817553\n",
       "0  BERTopic        0.766912      0.108             0.5633    53.813119\n",
       "1   KeyBERT        0.582433      0.166             0.5733    53.348328"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def final_model_ranking(purity_df, stability_df, gemini_explanation_df):\n",
    "    # Compute average Stability per model\n",
    "    stabilities = []\n",
    "    for model in purity_df[\"Model\"]:\n",
    "        avg_stability = stability_df.loc[stability_df[\"Model\"] == model, \"Average Matched Stability\"].mean()\n",
    "        stabilities.append(round(avg_stability, 3) if not np.isnan(avg_stability) else 0)\n",
    "\n",
    "\n",
    "    # Add Stability column\n",
    "    purity_df[\"Stability\"] = stabilities\n",
    "\n",
    "    # Merge with Gemini Scores\n",
    "    merged_df = pd.merge(purity_df, gemini_explanation_df, on=\"Model\")\n",
    "\n",
    "    # --- Weights ---\n",
    "    w1 = 0.1  # Purity\n",
    "    w2 = 0.1  # Stability\n",
    "    w3 = 0.8  # Gemini Score\n",
    "\n",
    "    # Normalize Gemini scores\n",
    "    merged_df[\"Gemini Normalized\"] = merged_df[\"Average Score\"] / 100\n",
    "\n",
    "    # Compute Final Score\n",
    "    merged_df[\"Final Score\"] = 100*(\n",
    "        w1 * merged_df[\"Average Purity\"] +\n",
    "        w2 * merged_df[\"Stability\"] +\n",
    "        w3 * merged_df[\"Gemini Normalized\"]\n",
    "    )\n",
    "\n",
    "    # --- Remove Average Score ---\n",
    "    merged_df = merged_df.drop(columns=[\"Average Score\"])\n",
    "\n",
    "    # --- Reorder Columns ---\n",
    "    columns_order = [\"Model\", \"Average Purity\", \"Stability\", \"Gemini Normalized\", \"Final Score\"]\n",
    "    merged_df = merged_df[columns_order]\n",
    "\n",
    "    # --- Display ---\n",
    "    merged_df = merged_df.sort_values(\"Final Score\", ascending=False)\n",
    "    print(\"=== Final Model Ranking (with Gemini normalized properly) ===\")\n",
    "    display(merged_df)\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "ranking_df = final_model_ranking(purity_df, stability_df, explanation_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gemini as the Primary Evaluation Signal\n",
    "In our final ranking, Gemini emerged as the top-performing labeling method â€” and deservedly so.\n",
    "\n",
    "Unlike the other metrics (Purity and Stability), which rely on surface-level heuristics (e.g., keyword presence or label overlap), Gemini provides a semantic, high-level understanding of the topic-label alignment. It evaluates whether the generated labels truly reflect the underlying meaning of the clustered texts â€” something that keyword matching alone cannot capture.\n",
    "\n",
    "Because of this, we assign Gemini a significantly higher weight (80%) in the final score.\n",
    "The Purity and Stability metrics, while useful for identifying obvious issues like inconsistent or irrelevant labels, are limited in their ability to assess quality from a human perspective.\n",
    "\n",
    "By prioritizing Gemini, we ground our evaluation in a model that reflects human-like judgment and intuition, ensuring that the labels selected are not only consistent â€” but actually meaningful."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BERTopic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
