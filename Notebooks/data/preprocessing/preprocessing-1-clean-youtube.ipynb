{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing - From Youtube To Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset_name = \"honey_scam_500\"\n",
    "dataset_path = f\"youtube-comments/{dataset_name}.csv\"\n",
    "\n",
    "# Load the comments dataset\n",
    "dataset_df = pd.read_csv(dataset_path) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import html\n",
    "\n",
    "def clean_comment(comment):\n",
    "    unescaped_comment = html.unescape(comment)  # Unescape HTML entities\n",
    "    soup = BeautifulSoup(unescaped_comment, 'html.parser')  # Parse HTML\n",
    "    return soup.get_text(separator='')  # Extract and clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dataset_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df['text'] = dataset_df['text'].apply(clean_comment)\n",
    "display(dataset_df.head(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df.iloc[5]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df.to_csv(dataset_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todo\n",
    "Convert Emojis ?\n",
    "uncensor bad words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"all mentions (e.g., @users), hashtags, unknown signs, and emojis were removed. Original sentences were used for BERTopic since algorithms rely on an embedding approach, and keeping the original structure of the text is vital for transformer models.\"\n",
    "https://pmc.ncbi.nlm.nih.gov/articles/PMC9120935/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BERTopic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
